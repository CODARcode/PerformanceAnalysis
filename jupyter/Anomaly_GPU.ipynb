{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection in GPU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('functimes_combined.dat', \"r\") as f:\n",
    "    raw_data = [x.strip(\"\\n\").split() for x in f.readlines()]\n",
    "\n",
    "run_time = {}\n",
    "for i in raw_data:\n",
    "    func_name = []\n",
    "    for j in range(len(i)):\n",
    "        if not i[j].isdigit(): # get the func name\n",
    "            func_name.append(i[j])\n",
    "        else:\n",
    "            runtime = [int(x) for x in i[j:]]\n",
    "            key = \"_\".join(func_name).strip('\\\"')\n",
    "            # if a key already exists, then the new runtime list will append to the existing list\n",
    "            value = run_time.get(key)\n",
    "            if value == None:\n",
    "                run_time[key] = runtime\n",
    "            else:\n",
    "                run_time[key] = value.append(runtime)\n",
    "    \n",
    "            break # exit the loop once we find the position of the first numeric element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the length of` (run_time)` isn't equal to the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(run_time), len(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can collect the function name and check if anything is wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun_name = []\n",
    "\n",
    "for i in raw_data:\n",
    "    func_name = []\n",
    "    for j in range(len(i)):\n",
    "        if not i[j].isdigit(): \n",
    "            func_name.append(i[j]) # get the func name\n",
    "    key = \"_\".join(func_name).strip('\\\"')\n",
    "    fun_name.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, i in zip(fun_name, range(len(fun_name))):\n",
    "    try:\n",
    "        run_time[name]\n",
    "    except:\n",
    "        print(name, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check the original data file we will notice this is really the case. No runtime data follows `TOTAL`. And their is a blank entry in line 354."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's select the most frequently called functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = []\n",
    "for key, value in run_time.items():\n",
    "    len_list.append(len(run_time[key]))\n",
    "\n",
    "df_len = pd.DataFrame(len_list, index=run_time.keys())\n",
    "df_len = df_len.reset_index()\n",
    "df_len = df_len.rename(columns={\"index\": 'func_name', 0:'call_times'})\n",
    "df_len = df_len.sort_values('call_times', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = df_len[df_len['call_times'] > 10000]\n",
    "subset = df_freq.sample(frac = 0.5, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_portion(dic, func, frac = 0.3):    \n",
    "    func_runtime = dic[func]\n",
    "    # total length of the sample\n",
    "    length = int(len(func_runtime) * frac)\n",
    "    # select where to start taking the data\n",
    "    start_position = np.random.randint(0, (len(func_runtime) - length))\n",
    "    sample_runtime = func_runtime[start_position : start_position + length]\n",
    "    df_sample = pd.DataFrame({'run_time' : sample_runtime})\n",
    "    df_sample.name = func\n",
    "    \n",
    "    return df_sample   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(len(subset))\n",
    "func_name = subset.iloc[i].func_name\n",
    "sample = sample_portion(run_time, func_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "plt.rcParams['figure.figsize'] = [13, 5.]\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['legend.fontsize'] = 17\n",
    "plt.rcParams['legend.frameon'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(outlier, normal, method, *args):\n",
    "    total_points = len(outlier) + len(normal)\n",
    "    ratio = len(outlier) / total_points\n",
    "    para = args\n",
    "    plt.figure()\n",
    "    if ratio >= 0.01:\n",
    "        plt.title(\"{}, outlier_ratio={:.2f}\".format(method, ratio))\n",
    "    else:\n",
    "        plt.title(\"{}, {} outliers in {} points\".format(method, len(outlier), total_points))\n",
    "    g = plt.scatter(normal.index,  normal['run_time'], c='green', s=15, edgecolor='k')\n",
    "    h = plt.scatter(outlier.index, outlier['run_time'], c='red', s=55, edgecolor='k')\n",
    "    #plt.xlabel('timestamp', fontsize=15)\n",
    "    plt.ylabel('run_time', fontsize=15)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.axis('tight')\n",
    "    plt.legend([g, h],[\"Normal\",\"Outlier\"], prop={'size': 15})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_gaussian(df, window_frac = 0.2, c = 6, plot = True):\n",
    "    window = int(window_frac * len(df))\n",
    "    mean = df.run_time.rolling(window = window).mean()\n",
    "    mean.iloc[:(window-1)] = mean.iloc[window]\n",
    "    std = df.run_time.rolling(window = window).std()\n",
    "    std.iloc[:(window-1)] = std.iloc[window]\n",
    "\n",
    "    upper = mean + c * std\n",
    "    lower = mean - c * std\n",
    "    a1 = df.run_time > upper\n",
    "    a2 = df.run_time < lower\n",
    "    \n",
    "    anomalies = np.logical_or(a1, a2)\n",
    "    normal = np.logical_not(anomalies)\n",
    "    outlier = df[anomalies]\n",
    "    normal = df[normal]\n",
    "    \n",
    "    if plot:\n",
    "        plot_result(outlier, normal, 'Gaussian')    \n",
    "    return outlier, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_gaussian(sample, plot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(10): # test 10 random samples\n",
    "    np.random.seed(i)\n",
    "    j = np.random.randint(len(subset))\n",
    "    func_name = subset.iloc[j].func_name\n",
    "    #print(j, func_name)\n",
    "    sample = sample_portion(run_time, func_name)\n",
    "    moving_gaussian(sample, plot=True);\n",
    "end = time.time()\n",
    "print(\"total time used: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Quantile Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_quantile(df, window_frac = 0.15, c = 6, plot=True):\n",
    "    window = int(window_frac * len(df))\n",
    "    q1 = df.run_time.rolling(window = window).quantile(0.1)\n",
    "    q3 = df.run_time.rolling(window = window).quantile(0.9)\n",
    "    q1.iloc[:(window-1)] = q1.iloc[window]\n",
    "    q3.iloc[:(window-1)] = q3.iloc[window]\n",
    "\n",
    "    upper = q3 + c * (q3 - q1)\n",
    "    lower = q1 - c * (q3 - q1)\n",
    "    a1 = df.run_time > upper\n",
    "    a2 = df.run_time < lower\n",
    "    \n",
    "    anomalies = np.logical_or(a1, a2)\n",
    "    normal = np.logical_not(anomalies)\n",
    "    outlier = df[anomalies]\n",
    "    normal = df[normal]\n",
    "    \n",
    "    if plot:\n",
    "        plot_result(outlier, normal, 'Tukey')        \n",
    "    return outlier, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(10): # test 10 random samples\n",
    "    np.random.seed(i)\n",
    "    j = np.random.randint(len(subset))\n",
    "    func_name = subset.iloc[j].func_name\n",
    "    sample = sample_portion(run_time, func_name)\n",
    "    moving_quantile(sample, plot=True);\n",
    "end = time.time()\n",
    "print(\"total time used: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinClusterDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MinClusterDetector` treats multivariate time series as independent points in a high-dimensional space, divides them into clusters, and identifies values in the smallest cluster as anomalous. This may help capturing outliers in high-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adtk.data import validate_series\n",
    "\n",
    "def transform_adtk(df):\n",
    "    tmp = pd.to_datetime(df.index.values, unit='D',\n",
    "               origin=pd.Timestamp('2020-01-01'))\n",
    "    idx = pd.Index(tmp, name='timestamp')\n",
    "    \n",
    "    data = {'run_time': df['run_time'].values}\n",
    "    df_trans = pd.DataFrame(data=data, index=idx)\n",
    "    df_trans.name = df.name\n",
    "    return df_trans\n",
    "\n",
    "sample_adtk = transform_adtk(sample)\n",
    "validate_series(sample_adtk); # validate the dataframe conforms with adtk requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adtk.detector import MinClusterDetector\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def min_cluster(df, n_clusters = 2, plot=True):\n",
    "    min_cluster_detector = MinClusterDetector(KMeans(n_clusters = n_clusters))\n",
    "    df = transform_adtk(df)\n",
    "    anomalies = min_cluster_detector.fit_detect(df)\n",
    "    normal = df[~anomalies]\n",
    "    outlier = df[anomalies]\n",
    "    \n",
    "    if plot:\n",
    "        plot_result(outlier, normal, 'Min Cluster')\n",
    "    \n",
    "    return outlier, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(10): # test 10 random samples\n",
    "    np.random.seed(i)\n",
    "    j = np.random.randint(len(subset))\n",
    "    func_name = subset.iloc[j].func_name\n",
    "    sample = sample_portion(run_time, func_name)\n",
    "    min_cluster(sample, plot=True);\n",
    "end = time.time()\n",
    "print(\"total time used: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative Entropy Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from base import NAB_Dataset\n",
    "from relative_entropy_detector import RelativeEntropyDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_entropy(df, window_frac = 0.01, bins = 40, plot = True):\n",
    "    re_ad = RelativeEntropyDetector(df)\n",
    "    window = int(window_frac * len(df))\n",
    "    re_ad.W = window\n",
    "    re_ad.N_bins = bins\n",
    "    result = re_ad.run();\n",
    "    outlier = result[result.anomaly_score > 0]\n",
    "    normal = result[result.anomaly_score == 0]\n",
    "    if plot:\n",
    "        plot_result(outlier, normal, \"RE\")\n",
    "    return outlier, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(10): # test 10 random samples\n",
    "    np.random.seed(i)\n",
    "    j = np.random.randint(len(subset))\n",
    "    func_name = subset.iloc[j].func_name\n",
    "    sample = sample_portion(run_time, func_name)\n",
    "    relative_entropy(sample, plot=True);\n",
    "end = time.time()\n",
    "print(\"total time used: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN-CAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A short introduction of KNN-CAD is [here](https://github.com/empyriumz/NAB/tree/master/nab/detectors/knncad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knncad_detector import KnncadDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KnncadDetector(sample, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.iloc[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_cad(df, k = 8, dim = 2, plot=True):\n",
    "    knn = KnncadDetector(df, 0.02)\n",
    "    knn.dim = dim\n",
    "    knn.k = k\n",
    "    result = knn.run()\n",
    "    out = result[result[1] > result[1].quantile(0.99)]\n",
    "    normal = result[result[1] <= result[1].quantile(0.99)]\n",
    "    out = out.rename(columns={0: 'run_time'})\n",
    "    normal = normal.rename(columns={0: 'run_time'})\n",
    "    if plot:\n",
    "        plot_result(out, normal, 'knn')\n",
    "    return out, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(10): # test 10 random samples\n",
    "    np.random.seed(i)\n",
    "    j = np.random.randint(len(subset))\n",
    "    func_name = subset.iloc[j].func_name\n",
    "    sample = sample_portion(run_time, func_name)\n",
    "    knn_cad(sample.iloc[:int(0.3*len(sample))], plot=True);\n",
    "end = time.time()\n",
    "print(\"total time used: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elliptic Envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import EllipticEnvelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EllipticEnvelope(contamination=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBLOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.cblof import CBLOF\n",
    "\n",
    "def cblof(df, n_clusters=8, contamination=0.01, cut_off = 15, plot=True):\n",
    "    x_ = df.run_time.values.reshape(-1, 1)\n",
    "    high, low = x_.max(), np.quantile(x_, q=0.05)\n",
    "    # enforce cutoff rule\n",
    "    if (high - low) / low <= cut_off:\n",
    "        out, normal = pd.DataFrame({'run_time':[]}), df\n",
    "        print(\"cutoff rule applied with cutoff={}\".format(cut_off))\n",
    "    else:    \n",
    "        clf = CBLOF(n_clusters = n_clusters, contamination = contamination)\n",
    "        clf.fit(x_)\n",
    "        result = clf.predict(x_)\n",
    "        tmp = pd.DataFrame({'anomaly_score': result, 'run_time': x_.reshape(-1)})\n",
    "        out = tmp[(tmp.anomaly_score > 0)]\n",
    "        normal = tmp[(tmp.anomaly_score == 0)]\n",
    "\n",
    "    if plot:\n",
    "        plot_result(out, normal, 'CB_LOF')\n",
    "    return out, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(10): # test 10 random samples\n",
    "    np.random.seed(71*i+1)\n",
    "    j = np.random.randint(len(subset))\n",
    "    func_name = subset.iloc[j].func_name\n",
    "    sample = sample_portion(run_time, func_name, frac=0.5)\n",
    "    cblof(sample, plot=True);\n",
    "end = time.time()\n",
    "print(\"total time used: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's benchmark with the traditional `LOF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "def lof(df, contamination = 0.01, n_neighbors = 100, plot = True):\n",
    "    clf = LocalOutlierFactor(n_neighbors=n_neighbors, # broader estimation \n",
    "                             algorithm=\"auto\", leaf_size=30, metric=\"minkowski\", p=2, \n",
    "                             metric_params=None, contamination=contamination, n_jobs=-1)\n",
    "    y_pred = clf.fit_predict(df.run_time.values.reshape(-1, 1))\n",
    "    outlier = df[y_pred == -1]\n",
    "    normal = df[y_pred == +1]\n",
    "    if plot:\n",
    "        plot_result(outlier, normal, 'lof')\n",
    "    return outlier, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(10): # test 10 random samples\n",
    "    np.random.seed(i)\n",
    "    j = np.random.randint(len(subset))\n",
    "    func_name = subset.iloc[j].func_name\n",
    "    sample = sample_portion(run_time, func_name)\n",
    "    lof(sample, plot=True);\n",
    "end = time.time()\n",
    "print(\"total time used: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see `CBLOF` is better and much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COPOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.copod import COPOD\n",
    "\n",
    "def cop(df, contamination=0.01, cut_off = 20, plot=True):\n",
    "    x_ = df.run_time.values.reshape(-1, 1)    \n",
    "    # enforce cutoff rule\n",
    "    highest, high, low = x_.max(), np.quantile(x_, q=0.99), np.quantile(x_, q=0.1)\n",
    "    if (highest - low) / low <= cut_off:\n",
    "        out, normal = pd.DataFrame({'run_time':[]}), df\n",
    "        print(\"cutoff rule applied with cutoff={}\".format(cut_off))\n",
    "    else:\n",
    "        if (high - low)/low < 0.5: # if majority of the data is narrowly distributed, lower the outlier ratio\n",
    "            contamination = 0.1 * contamination\n",
    "            print('contamination lowered with c={}'.format(contamination))\n",
    "        clf = COPOD(contamination = contamination) \n",
    "        clf.fit(x_)\n",
    "        result = clf.predict(x_)\n",
    "        tmp = pd.DataFrame({'anomaly_score': result, 'run_time': x_.reshape(-1)})\n",
    "        out = tmp[(tmp.anomaly_score > 0)]\n",
    "        normal = tmp[(tmp.anomaly_score == 0)]\n",
    "        \n",
    "    if plot:\n",
    "        plot_result(out, normal, 'COPOD')\n",
    "    return out, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(10): # test 10 random samples\n",
    "    seed = 78*i+31\n",
    "    np.random.seed()\n",
    "    j = np.random.randint(len(subset))\n",
    "    func_name = subset.iloc[j].func_name\n",
    "    sample = sample_portion(run_time, func_name, frac=0.5)\n",
    "    print(\"seed = {}, func_name:{}\".format(seed, func_name))\n",
    "    cop(sample, plot=True);\n",
    "end = time.time()\n",
    "print(\"total time used: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.feature_bagging import FeatureBagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_bag = FeatureBagging(contamination=0.01, max_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_bag.fit(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HBOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "def hbos(df, contamination=0.01, n_bins = 10, alpha = 0.2, cut_off = 20, plot=True):\n",
    "    x_ = df.run_time.values.reshape(-1, 1)\n",
    "    highest, high, low = x_.max(), np.quantile(x_, q=0.99), np.quantile(x_, q=0.1)\n",
    "    # enforce cutoff rule\n",
    "    if (highest - low) / low <= cut_off:\n",
    "        out, normal = pd.DataFrame({'run_time':[]}), df\n",
    "        print(\"cutoff rule applied with cutoff={}\".format(cut_off))\n",
    "    else:\n",
    "        if (high - low) / low < 0.5: # if majority of the data is narrowly distributed, lower the outlier ratio\n",
    "            contamination = 0.1 * contamination\n",
    "            print('contamination lowered with c={}'.format(contamination))\n",
    "        clf = HBOS(n_bins = n_bins, alpha = alpha, contamination = contamination) \n",
    "        clf.fit(x_)\n",
    "        result = clf.predict(x_)\n",
    "        tmp = pd.DataFrame({'anomaly_score': result, 'run_time': x_.reshape(-1)})\n",
    "        out = tmp[(tmp.anomaly_score > 0)]\n",
    "        normal = tmp[(tmp.anomaly_score == 0)]\n",
    "        \n",
    "    if plot:\n",
    "        plot_result(out, normal, 'hbos')\n",
    "    return out, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(10): # test 10 random samples\n",
    "    seed = 1122*i+91\n",
    "    np.random.seed(seed)\n",
    "    j = np.random.randint(len(subset))\n",
    "    func_name = subset.iloc[j].func_name\n",
    "    print(\"seed={}\".format(seed), func_name)\n",
    "    #print()\n",
    "    sample = sample_portion(run_time, func_name, frac=0.5)\n",
    "    hbos(sample, plot=True);\n",
    "end = time.time()\n",
    "print(\"total time used: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LODA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.loda import LODA\n",
    "\n",
    "def loda(df, contamination=0.01, n_bins=10, n_random_cuts=100, cut_off=15, plot=True):\n",
    "    \n",
    "    x_ = df.run_time.values.reshape(-1, 1)\n",
    "    highest, high, low = x_.max(), np.quantile(x_, q=0.99), np.quantile(x_, q=0.25)\n",
    "    if df.run_time.std() == 0:\n",
    "        out, normal = pd.DataFrame({'run_time':[]}), df\n",
    "        print(\"Data has no variation, No outlier !\")\n",
    "\n",
    "    elif (highest - low) / low <= cut_off:\n",
    "        out, normal = pd.DataFrame({'run_time':[]}), df\n",
    "        print(\"cutoff rule applied with cutoff={}\".format(cut_off))\n",
    "\n",
    "    else:  \n",
    "        if (high - low)/low < 0.5: # if majority of the data is narrowly distributed, lower the outlier ratio\n",
    "            contamination = 0.1 * contamination\n",
    "            print('contamination lowered with c={}'.format(contamination))\n",
    "        clf = LODA(n_bins = n_bins, n_random_cuts=n_random_cuts, contamination = contamination) \n",
    "        clf.fit(x_)\n",
    "        result = clf.predict(x_)\n",
    "        tmp = pd.DataFrame({'anomaly_score': result, 'run_time': x_.reshape(-1)})\n",
    "        out = tmp[(tmp.anomaly_score > 0)]\n",
    "        normal = tmp[(tmp.anomaly_score == 0)]\n",
    "        \n",
    "    if plot:\n",
    "        plot_result(out, normal, 'LODA')\n",
    "    return out, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "for i in range(10): # test 10 random samples\n",
    "    seed = 78*i+131\n",
    "    np.random.seed()\n",
    "    j = np.random.randint(len(subset))\n",
    "    func_name = subset.iloc[j].func_name\n",
    "    sample = sample_portion(run_time, func_name, frac=0.55)\n",
    "    print(\"seed = {}, func_name:{}\".format(seed, func_name))\n",
    "    loda(sample, plot=True);\n",
    "\n",
    "end = time.time()\n",
    "print(\"total time used: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOCI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory leaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.loci import LOCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = sample.run_time.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loci = LOCI(contamination=0.01, alpha=0.5, k=3)\n",
    "loci.fit(x_)\n",
    "result = loc.predict(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locally Selective Combination of Parallel Outlier Ensembles (LSCP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.lscp import LSCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detector_list = [LODA(), HBOS(), COPOD()]\n",
    "detector_list = [LODA(), HBOS()]\n",
    "lscp = LSCP(detector_list, local_region_size=30, local_max_features=0.5, n_bins=10, contamination=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lscp.fit(x_[:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lscp.predict(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It suffers from memory leaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.cof import COF\n",
    "\n",
    "\n",
    "def cof(df, n_neighbors=20, contamination=0.01, cut_off = 20, plot=True):    \n",
    "    x_ = df.run_time.values.reshape(-1, 1)\n",
    "    if (x_.max() - x_.min()) / x_.min() <= cut_off:\n",
    "        out, normal = None, df\n",
    "    else:    \n",
    "        clf = COF(n_neighbors = n_neighbors, contamination = contamination) \n",
    "        clf.fit(x_)\n",
    "        result = clf.predict(x_)\n",
    "        tmp = pd.DataFrame(np.stack([result, x_.reshape(-1)], axis=1), columns={'run_time', 'anomaly_score'})\n",
    "        out = tmp[(tmp.anomaly_score > 0)]\n",
    "        normal = tmp[(tmp.anomaly_score == 0)]\n",
    "    if plot:\n",
    "        plot_result(out, normal, 'cof')\n",
    "    return out, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(10): # test 10 random samples\n",
    "    np.random.seed(8*i+1)\n",
    "    j = np.random.randint(len(subset))\n",
    "    func_name = subset.iloc[j].func_name\n",
    "    sample = sample_portion(run_time, func_name)\n",
    "    cof(sample, plot=True);\n",
    "end = time.time()\n",
    "print(\"total time used: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
